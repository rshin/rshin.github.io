# Types of links
# - paper
# - code
# - slides
# - video
# - project page

# Preprints
- title: "BenchCLAMP: A Benchmark for Evaluating Language Models on Semantic Parsing"
  authors:
    [
      Subhro Roy,
      Sam Thomson,
      Tongfei Chen,
      Richard Shin,
      Adam Pauls,
      Jason Eisner,
      Benjamin Van Durme,
    ]
  published:
    - venue: arxiv
      date: 2022-06-21
  links:
    - pdf: https://arxiv.org/pdf/2206.10668.pdf
    - code: https://github.com/microsoft/semantic_parsing_as_constrained_lm
  abstract: >
    We introduce BenchCLAMP, a Benchmark to evaluate Constrained LAnguage Model
    Parsing, which produces semantic outputs based on the analysis of input text
    through constrained decoding of a prompted or fine-tuned language model.
    Developers of pretrained language models currently benchmark on
    classification, span extraction and free-text generation tasks. Semantic
    parsing is neglected in language model evaluation because of the complexity
    of handling task-specific architectures and representations. Recent work has
    shown that generation from a prompted or fine-tuned language model can
    perform well at semantic parsing when the output is constrained to be a
    valid semantic representation. BenchCLAMP includes context-free grammars for
    six semantic parsing datasets with varied output meaning representations, as
    well as a constrained decoding interface to generate outputs covered by
    these grammars. We provide low, medium, and high resource splits for each
    dataset, allowing accurate comparison of various language models under
    different data regimes. Our benchmark supports both prompt-based learning as
    well as fine-tuning, and provides an easy-to-use toolkit for language model
    developers to evaluate on semantic parsing.

- title: Hierarchical Variational Imitation Learning of Control Programs
  authors:
    [
      Roy Fox,
      Richard Shin,
      William Paul,
      Yitian Zou,
      Dawn Song,
      Ken Goldberg,
      Pieter Abbeel,
      Ion Stoica,
    ]
  published:
    - venue: arxiv
      date: 2019-12-29
  links:
    - pdf: https://arxiv.org/pdf/1912.12612
  abstract: >
    Autonomous agents can learn by imitating teacher demonstrations of the
    intended behavior. Hierarchical control policies are ubiquitously useful for
    such learning, having the potential to break down structured tasks into
    simpler sub-tasks, thereby improving data efficiency and generalization. In
    this paper, we propose a variational inference method for imitation learning
    of a control policy represented by parametrized hierarchical procedures
    (PHP), a program-like structure in which procedures can invoke
    sub-procedures to perform sub-tasks. Our method discovers the hierarchical
    structure in a dataset of observation-action traces of teacher
    demonstrations, by learning an approximate posterior distribution over the
    latent sequence of procedure calls and terminations. Samples from this
    learned distribution then guide the training of the hierarchical control
    policy. We identify and demonstrate a novel benefit of variational inference
    in the context of hierarchical imitation learning: in decomposing the policy
    into simpler procedures, inference can leverage acausal information that is
    unused by other methods. Training PHP with variational inference outperforms
    LSTM baselines in terms of data efficiency and generalization, requiring
    less than half as much data to achieve a 24% error rate in executing the
    bubble sort algorithm, and to achieve no error in executing Karel programs.
  
# Conference publications
- title: "Privacy-Preserving Domain Adaptation of Semantic Parsers"
  authors:
    [
      Fatemehsadat Mireshghallah,
      Yu Su,
      Tatsunori Hashimoto,
      Jason Eisner,
      Richard Shin
    ]
  published:
    - venue: acl
      date: 2023-07-10
  links:
    - pdf: https://arxiv.org/pdf/2212.10520.pdf
  abstract: >
    Task-oriented dialogue systems often assist users with personal or
    confidential matters. For this reason, the developers of such a system are
    generally prohibited from observing actual usage. So how can they know where
    the system is failing and needs more training data or new functionality? In
    this work, we study ways in which realistic user utterances can be generated
    synthetically, to help increase the linguistic and functional coverage of
    the system, without compromising the privacy of actual users. To this end,
    we propose a two-stage Differentially Private (DP) generation method which
    first generates latent semantic parses, and then generates utterances based
    on the parses. Our proposed approach improves MAUVE by 3.8× and parse tree
    node-type overlap by 1.4× relative to current approaches for private
    synthetic data generation, improving both on fluency and semantic coverage.
    We further validate our approach on a realistic domain adaptation task of
    adding new functionality from private user data to a semantic parser, and
    show gains of 1.3× on its accuracy with the new feature.

- title: Few-Shot Semantic Parsing with Language Models Trained On Code
  authors: [Richard Shin, Benjamin Van Durme]
  published:
    - venue: naacl
      date: 2022-07-12
      format: short paper
  links:
    - pdf: https://aclanthology.org/2022.naacl-main.396.pdf
  abstract: >
    Large language models can perform semantic parsing with little training
    data, when prompted with in-context examples. It has been shown that this
    can be improved by formulating the problem as paraphrasing into canonical
    utterances, which casts the underlying meaning representation into a
    controlled natural language-like representation. Intuitively, such models
    can more easily output canonical utterances as they are closer to the
    natural language used for pre-training. Recently, models also pre-trained on
    code, like OpenAI Codex, have risen in prominence. For semantic parsing
    tasks where we map natural language into code, such models may prove more
    adept at it. In this paper, we test this hypothesis and find that Codex
    performs better on such tasks than equivalent GPT-3 models. We evaluate on
    Overnight and SMCalFlow and find that unlike GPT-3, Codex performs similarly
    when targeting meaning representations directly, perhaps because meaning
    representations are structured similar to code in these datasets.

- title: Addressing Resource and Privacy Constraints in Semantic Parsing Through Data Augmentation
  authors: 
    [
      Kevin Yang,
      Olivia Deng,
      Charles Chen,
      Richard Shin,
      Subhro Roy,
      Benjamin Van Durme,
    ]
  published:
    - venue: acl-findings
      date: 2022-05-23
  links:
    - pdf: https://aclanthology.org/2022.findings-acl.291.pdf
  abstract: >
    We introduce a novel setup for low-resource task-oriented semantic parsing
    which incorporates several constraints that may arise in real-world
    scenarios: (1) lack of similar datasets/models from a related domain, (2)
    inability to sample useful logical forms directly from a grammar, and (3)
    privacy requirements for unlabeled natural utterances. Our goal is to
    improve a low-resource semantic parser using utterances collected through
    user interactions. In this highly challenging but realistic setting, we
    investigate data augmentation approaches involving generating a set of
    structured canonical utterances corresponding to logical forms, before
    simulating corresponding natural language and filtering the resulting pairs.
    We find that such approaches are effective despite our restrictive setup: in
    a low-resource setting on the complex SMCalFlow calendaring dataset (Andreas
    et al. 2020), we observe 33% relative improvement over a non-data-augmented
    baseline in top-1 match.

- title: Guided K-best Selection for Semantic Parsing Annotation
  authors:
    [
      Anton Belyy,
      Chieh-Yang Huang,
      Jacob Andreas,
      Emmanouil Antonios Platanios,
      Sam Thomson,
      Richard Shin,
      Subhro Roy,
      Aleksandr Nisnevich,
      Charles Chen,
      Benjamin Van Durme,
    ]
  published:
    - venue: acl
      date: 2022-05-23
      format: demo track
  links:
    - pdf: https://aclanthology.org/2022.acl-demo.11.pdf
  abstract: >
    Collecting data for conversational semantic parsing is a time-consuming and
    demanding process. In this paper we consider, given an incomplete dataset
    with only a small amount of data, how to build an AI-powered
    human-in-the-loop process to enable efficient data collection. A guided
    K-best selection process is proposed, which (i) generates a set of possible
    valid candidates; (ii) allows users to quickly traverse the set and filter
    incorrect parses; and (iii) asks users to select the correct parse, with
    minimal modification when necessary. We investigate how to best support
    users in efficiently traversing the candidate set and locating the correct
    parse, in terms of speed and accuracy. In our user study, consisting of five
    annotators labeling 300 instances each, we find that combining keyword
    searching, where keywords can be used to query relevant candidates, and
    keyword suggestion, where representative keywords are automatically
    generated, enables fast and accurate annotation.

- title: Constrained Language Models Yield Few-Shot Semantic Parsers
  authors:
    [
      Richard Shin,
      Christopher H. Lin,
      Sam Thomson,
      Charles Chen,
      Subhro Roy,
      Emmanouil Antonios Platanios,
      Adam Pauls,
      Dan Klein,
      Jason Eisner,
      Benjamin Van Durme,
    ]
  published:
    - venue: emnlp
      date: 2021-11-10
  links:
    - pdf: https://aclanthology.org/2021.emnlp-main.608.pdf
    - code: https://github.com/microsoft/semantic_parsing_with_constrained_lm
  abstract: >
    We explore the use of large pretrained language models as few-shot semantic
    parsers. The goal in semantic parsing is to generate a structured meaning
    representation given a natural language input. However, language models are
    trained to generate natural language. To bridge the gap, we use language
    models to paraphrase inputs into a controlled sublanguage resembling English
    that can be automatically mapped to a target meaning representation. Our
    results demonstrate that with only a small amount of data and very little
    code to convert into English-like representations, our blueprint for rapidly
    bootstrapping semantic parsers leads to surprisingly effective performance
    on multiple community tasks, greatly exceeding baseline methods also trained
    on the same limited data.
    
- title: "RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers"
  authors:
    [
      Bailin Wang*,
      Richard Shin*,
      Xiaodong Liu,
      Oleksandr Polozov,
      Matthew Richardson,
    ]
  published:
    - venue: acl
      date: 2020-07-06
  links:
    - pdf: https://aclanthology.org/2020.acl-main.677.pdf
    - code: https://github.com/microsoft/rat-sql
  abstract: >
    When translating natural language questions into SQL queries to answer
    questions from a database, contemporary semantic parsing models struggle
    to generalize to unseen database schemas. The generalization challenge
    lies in (a) encoding the database relations in an accessible way for the
    semantic parser, and (b) modeling alignment between database columns and
    their mentions in a given query. We present a unified framework, based on
    the relation-aware self-attention mechanism, to address schema encoding,
    schema linking, and feature representation within a text-to-SQL encoder.
    On the challenging Spider dataset this framework boosts the exact match
    accuracy to 53.7%, compared to 47.4% for the state-of-the-art model
    unaugmented with BERT embeddings. In addition, we observe qualitative
    improvements in the model's understanding of schema linking and
    alignment.

# - title: Encoding Database Schemas with Relation-Aware Self-Attention for Text-to-SQL Parsers
#   authors: [Richard Shin]
#   published:
#     - venue: arxiv
#       date: 2019-06-20
#   links:
#     - pdf: https://arxiv.org/pdf/1906.11790
#     - code: https://github.com/rshin/seq2struct
#   abstract: >
#     When translating natural language questions into SQL queries to
#     answer questions from a database, we would like our methods to generalize
#     to domains and database schemas outside of the training set. To handle
#     complex questions and database schemas with a neural encoder-decoder
#     paradigm, it is critical to properly encode the schema as part of the input
#     with the question. In this paper, we use relation-aware self-attention
#     within the encoder so that it can reason about how the tables and columns
#     in the provided schema relate to each other and use this information in
#     interpreting the question. We achieve significant gains on the
#     recently-released Spider dataset with 42.94% exact match accuracy, compared
#     to the 18.96% reported in published work.

# Conference publications
- title: Program Synthesis and Semantic Parsing with Learned Code Idioms
  authors:
    [Richard Shin, Marc Brockschmidt, Miltiadis Allamanis, Oleksandr Polozov]
  published:
    - venue: neurips
      date: 2019-12-08
  links:
    - pdf: https://proceedings.neurips.cc/paper/2019/file/cff34ad343b069ea6920464ad17d4bcf-Paper.pdf
  abstract: >
    Program synthesis of general-purpose source code from natural language
    specifications is challenging due to the need to reason about high-level
    patterns in the target program and low-level implementation details at
    the same time. In this work, we present PATOIS, a system that allows a
    neural program synthesizer to explicitly interleave high-level and
    low-level reasoning at every generation step. It accomplishes this by
    automatically mining common code idioms from a given corpus,
    incorporating them into the underlying language for neural synthesis, and
    training a tree-based neural synthesizer to use these idioms during code
    generation. We evaluate PATOIS on two complex semantic parsing datasets
    and show that using learned code idioms improves the synthesizer's
    accuracy.

- title: Synthetic Datasets for Neural Program Synthesis
  authors:
    [
      Richard Shin,
      Neel Kant,
      Kavi Gupta,
      Christopher Bender,
      Brandon Trabucco,
      Rishabh Singh,
      Dawn Song,
    ]
  published:
    - venue: iclr
      date: 2019-05-06
  links:
    - pdf: https://openreview.net/pdf?id=ryeOSnAqYm
  abstract: >
    The goal of program synthesis is to automatically generate programs in a
    particular language from corresponding specifications, e.g. input-output
    behavior. Many current approaches achieve impressive results after training
    on randomly generated I/O examples in limited domain-specific languages
    (DSLs), as with string transformations in RobustFill. However, we
    empirically discover that applying test input generation techniques for
    languages with control flow and rich input space causes deep networks to
    generalize poorly to certain data distributions; to correct this, we
    propose a new methodology for controlling and evaluating the bias of
    synthetic data distributions over both programs and specifications. We
    demonstrate, using the Karel DSL and a small Calculator DSL, that training
    deep networks on these distributions leads to improved cross-distribution
    generalization performance.


- title: Improving Neural Program Synthesis with Inferred Execution Traces
  authors: [Richard Shin, Illia Polosukhin, Dawn Song]
  published:
    - venue: neurips
      date: 2018-12-08
      award: spotlight presentation
  links:
    - pdf: https://papers.nips.cc/paper/8107-improving-neural-program-synthesis-with-inferred-execution-traces.pdf
    - code: https://github.com/nearai/program_synthesis
  abstract: >
    The task of program synthesis, or automatically generating programs that
    are consistent with a provided specification, remains a challenging task
    in artificial intelligence. As in other fields of AI, deep learning-based
    end-to-end approaches have made great advances in program synthesis.
    However, more so than other fields such as computer vision, program
    synthesis provides greater opportunities to explicitly exploit structured
    information such as execution traces, which contain a superset of the
    information input/output pairs. While they are highly useful for program
    synthesis, as execution traces are more difficult to obtain than
    input/output pairs, we use the insight that we can split the process into
    two parts: infer the trace from the input/output example, then infer the
    program from the trace. This simple modification leads to
    state-of-the-art results in program synthesis in the Karel domain,
    improving accuracy to 81.3% from the 77.12% of prior work.

- title: Parametrized Hierarchical Procedures for Neural Programming
  authors:
    [
      Roy Fox,
      Richard Shin,
      Sanjay Krishnan,
      Ken Goldberg,
      Dawn Song,
      Ion Stoica,
    ]
  published:
    - venue: iclr
      date: 2018-05-02
  links:
    - pdf: https://openreview.net/pdf?id=rJl63fZRb
  abstract: >
    Neural programs are highly accurate and structured policies that perform
    algorithmic tasks by controlling the behavior of a computation mechanism.
    Despite the potential to increase the interpretability and the
    compositionality of the behavior of artificial agents, it remains
    difficult to learn from demonstrations neural networks that represent
    computer programs. The main challenges that set algorithmic domains apart
    from other imitation learning domains are the need for high accuracy, the
    involvement of specific structures of data, and the extremely limited
    observability. To address these challenges, we propose to model programs
    as Parametrized Hierarchical Procedures (PHPs). A PHP is a sequence of
    conditional operations, using a program counter along with the
    observation to select between taking an elementary action, invoking
    another PHP as a sub-procedure, and returning to the caller. We develop
    an algorithm for training PHPs from a set of supervisor demonstrations,
    only some of which are annotated with the internal call structure, and
    apply it to efficient level-wise training of multi-level PHPs. We show in
    two benchmarks, NanoCraft and long-hand addition, that PHPs can learn
    neural programs more accurately from smaller amounts of both annotated
    and unannotated demonstrations.

- title: Making Neural Programming Architectures Generalize via Recursion
  authors: [Jonathon Cai, Richard Shin, Dawn Song]
  published:
    - venue: iclr
      date: 2017-04-27
      award: best paper award
  links:
    - pdf: https://openreview.net/pdf?id=BkbY4psgg
  abstract: >
    Empirically, neural networks that attempt to learn programs from data
    have exhibited poor generalizability. Moreover, it has traditionally been
    difficult to reason about the behavior of these models beyond a certain
    level of input complexity. In order to address these issues, we propose
    augmenting neural architectures with a key abstraction: recursion. As an
    application, we implement recursion in the Neural Programmer-Interpreter
    framework on four tasks: grade-school addition, bubble sort, topological
    sort, and quicksort. We demonstrate superior generalizability and
    interpretability with small amounts of training data. Recursion divides
    the problem into smaller pieces and drastically reduces the domain of
    each neural network component, making it tractable to prove guarantees
    about the overall system’s behavior. Our experience suggests that in
    order for neural architectures to robustly learn program semantics, it is
    necessary to incorporate a concept like recursion.

- title: "PIANO: Proximity-based User Authentication on Voice-Powered Internet-of-Things Devices"
  authors:
    [
      Neil Zhenqiang Gong,
      Altay Ozen,
      Yu Wu,
      Xiaoyu Cao,
      Richard Shin,
      Dawn Song,
      Hongxia Jin,
      Xuan Bao,
    ]
  published:
    - venue: icdcs
      date: 2017-06-05
  links:
    - pdf: https://arxiv.org/pdf/1704.03118.pdf
  abstract: >
    Voice is envisioned to be a popular way for humans to interact with
    Internet-of-Things (IoT) devices. We propose a proximity-based user
    authentication method (called PIANO) for access control on such
    voice-powered IoT devices. PIANO leverages the built-in speaker,
    microphone, and Bluetooth that voice-powered IoT devices often already
    have. Specifically, we assume that a user carries a personal
    voice-powered device (e.g., smartphone, smartwatch, or smartglass), which
    serves as the user's identity. When another voice-powered IoT device of
    the user requires authentication, PIANO estimates the distance between
    the two devices by playing and detecting certain acoustic signals; PIANO
    grants access if the estimated distance is no larger than a user-selected
    threshold. We implemented a proof-of-concept prototype of PIANO. Through
    theoretical and empirical evaluations, we find that PIANO is secure,
    reliable, personalizable, and efficient.

- title: "ExploreKit: Automatic Feature Generation and Selection"
  authors: [Gilad Katz, Richard Shin, Dawn Song]
  published:
    - venue: icdm
      date: 2016-12-13
      format: short paper
  links:
    - pdf: https://people.eecs.berkeley.edu/~dawnsong/papers/icdm-2016.pdf
    - code: https://github.com/giladkatz/ExploreKit
  abstract: >
    Feature generation is one of the challenging aspects of machine learning.
    We present ExploreKit, a framework for automated feature generation.
    ExploreKit generates a large set of candidate features by combining
    information in the original features, with the aim of maximizing
    predictive performance according to user-selected criteria. To overcome
    the exponential growth of the feature space, ExploreKit uses a novel
    machine learning-based feature selection approach to predict the
    usefulness of new candidate features. This approach enables efficient
    identification of the new features and produces superior results compared
    to existing feature selection solutions. We demonstrate the effectiveness
    and robustness of our approach by conducting an extensive evaluation on
    25 datasets and 3 different classification algorithms. We show that
    ExploreKit can achieve classification-error reduction of 20% overall. Our
    code is available at https://github.com/giladkatz/ExploreKit.

- title: Latent Attention for If-Then Program Synthesis
  authors: [Xinyun Chen, Chang Liu, Richard Shin, Dawn Song, Mingcheng Chen]
  published:
    - venue: neurips
      date: 2016-12-08
  links:
    - pdf: https://papers.nips.cc/paper/6284-latent-attention-for-if-then-program-synthesis.pdf
  abstract: >
    Automatic translation from natural language descriptions into programs is
    a long-standing challenging problem. In this work, we consider a simple
    yet important sub-problem: translation from textual descriptions to
    If-Then programs. We devise a novel neural network architecture for this
    task which we train end-to-end. Specifically, we introduce Latent
    Attention, which computes multiplicative weights for the words in the
    description in a two-stage process with the goal of better leveraging the
    natural language structures that indicate the relevant parts for
    predicting program elements. Our architecture reduces the error rate by
    28.57% compared to prior art. We also propose a one-shot learning
    scenario of If-Then program synthesis and simulate it with our existing
    dataset. We demonstrate a variation on the training procedure for this
    scenario that outperforms the original procedure, significantly closing
    the gap to the model trained with all data.

- title: Recognizing Functions in Binaries with Neural Networks
  authors: [Richard Shin, Dawn Song, Reza Moazzezi]
  published:
    - venue: usenix-security
      date: 2015-08-12
  links:
    - pdf: https://www.usenix.org/system/files/conference/usenixsecurity15/sec15-paper-shin.pdf
  abstract: >
    Binary analysis facilitates many important applications like malware
    detection and automatically fixing vulnerable software. In this paper, we
    propose to apply artificial neural networks to solve important yet
    difficult problems in binary analysis. Specifically, we tackle the
    problem of function identification, a crucial first step in many binary
    analysis techniques. Although neural networks have undergone a
    renaissance in the past few years, achieving breakthrough results in
    multiple application domains such as visual object recognition, language
    modeling, and speech recognition, no researchers have yet attempted to
    apply these techniques to problems in binary analysis. Using a dataset
    from prior work, we show that recurrent neural networks can identify
    functions in binaries with greater accuracy and efficiency than the
    state-of-the-art machine-learning-based method. We can train the model an
    order of magnitude faster and evaluate it on binaries hundreds of times
    faster. Furthermore, it halves the error rate on six out of eight
    benchmarks, and performs comparably on the remaining two.

- title: Joint Link Prediction and Attribute Inference Using a Social-Attribute Network
  authors:
    [
      Neil Zhenqiang Gong,
      Ameet Talwalkar,
      Lester Mackey,
      Ling Huang,
      Richard Shin,
      Emil Stefanov,
      Elaine Shi,
      Dawn Song,
    ]
  published:
     - venue: tist
       date: 2014-04
  links:
     - pdf: https://www.cs.cmu.edu/~atalwalk/tist13.pdf
     - data: http://gonglab.pratt.duke.edu/google-dataset
  abstract: >
    The effects of social influence and homophily suggest that both network
    structure and node-attribute information should inform the tasks of link
    prediction and node-attribute inference. Recently, Yin et al. [2010a,
    2010b] proposed an attribute-augmented social network model, which we
    call Social-Attribute Network (SAN), to integrate network structure and
    node attributes to perform both link prediction and attribute inference.
    They focused on generalizing the random walk with a restart algorithm to
    the SAN framework and showed improved performance. In this article, we
    extend the SAN framework with several leading supervised and unsupervised
    link-prediction algorithms and demonstrate performance improvement for
    each algorithm on both link prediction and attribute inference. Moreover,
    we make the novel observation that attribute inference can help inform
    link prediction, that is, link-prediction accuracy is further improved by
    first inferring missing attributes. We comprehensively evaluate these
    algorithms and compare them with other existing algorithms using a novel,
    large-scale Google+ dataset, which we make publicly available
    (http://www.cs.berkeley.edu/~stevgong/gplus.html).

- title: On the Feasibility of Internet-Scale Author Identification
  authors: [Arvind Narayanan, Hristo Paskov, Neil Zhenqiang Gong, John Bethencourt, Emil Stefanov, Richard Shin, Dawn Song]
  published:
    - venue: ieee-sp
      date: 2012-05-20
  links:
    - pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6234420
  abstract: >
    We study techniques for identifying an anonymous author via linguistic
    stylometry, i.e., comparing the writing style against a corpus of texts
    of known authorship. We experimentally demonstrate the effectiveness of
    our techniques with as many as 100,000 candidate authors. Given the
    increasing availability of writing samples online, our result has serious
    implications for anonymity and free speech - an anonymous blogger or
    whistleblower may be unmasked unless they take steps to obfuscate their
    writing style. While there is a huge body of literature on authorship
    recognition based on writing style, almost none of it has studied corpora
    of more than a few hundred authors. The problem becomes qualitatively
    different at a large scale, as we show, and techniques from prior work
    fail to scale, both in terms of accuracy and performance. We study a
    variety of classifiers, both "lazy" and "eager," and show how to handle
    the huge number of classes. We also develop novel techniques for
    confidence estimation of classifier outputs. Finally, we demonstrate
    stylometric authorship recognition on texts written in different
    contexts. In over 20% of cases, our classifiers can correctly identify an
    anonymous author given a corpus of texts from 100,000 authors; in about
    35% of cases the correct author is one of the top 20 guesses. If we allow
    the classifier the option of not making a guess, via confidence
    estimation we are able to increase the precision of the top guess from
    20% to over 80% with only a halving of recall.

- title: "FreeMarket: Shopping for free in Android applications"
  authors: [Daniel Reynaud, Richard Shin, Thomas R. Magrino, Edward X. Wu, Dawn Song]
  published:
    - venue: ndss
      date: 2012-02-05
      format: extended abstract
  links:
    - pdf: https://www.ndss-symposium.org/wp-content/uploads/2017/09/05_2.pdf

- title: A Systematic Analysis of XSS Sanitization in Web Application Frameworks
  authors: [Joel Weinberger, Prateek Saxena, Devdatta Akhawe, Matthew Finifter, Richard Shin, Dawn Song]
  published:
    - venue: esorics
      date: 2011-09-12
  links:
    - pdf: https://people.eecs.berkeley.edu/~dawnsong/papers/2011%20systematic%20analysis%20xss
  abstract: >
    While most research on XSS defense has focused on techniques for securing
    existing applications and re-architecting browser mechanisms,
    sanitization remains the industry-standard defense mechanism. By
    streamlining and automating XSS sanitization, web application frameworks
    stand in a good position to stop XSS but have received little research
    attention. In order to drive research on web frameworks, we
    systematically study the security of the XSS sanitization abstractions
    frameworks provide. We develop a novel model of the web browser and
    characterize the challenges of XSS sanitization. Based on the model, we
    systematically evaluate the XSS abstractions in 14 major
    commercially-used web frameworks. We find that frameworks often do not
    address critical parts of the XSS conundrum. We perform an empirical
    analysis of 8 large web applications to extract the requirements of
    sanitization primitives from the perspective of real-world applications.
    Our study shows that there is a wide gap between the abstractions
    provided by frameworks and the requirements of applications.

- title: Inference and Analysis of Formal Models of Botnet Command and Control Protocols
  authors: [Chia Yuan Cho, Domagoj Babic, Richard Shin, Dawn Song]
  published:
    - venue: ccs
      date: 2010-10-04
  links:
    - pdf: https://people.eecs.berkeley.edu/~dawnsong/papers/2010%20inference%20p426-cho.pdf
  abstract: >
    We propose a novel approach to infer protocol state machines in the
    realistic high-latency network setting, and apply it to the analysis of
    botnet Command and Control (C &C) protocols. Our proposed techniques
    enable an order of magnitude reduction in the number of queries and time
    needed to learn a botnet C &C protocol compared to classic algorithms
    (from days to hours for inferring the MegaD C &C protocol). We also show
    that the computed protocol state machines enable formal analysis for
    botnet defense, including finding the weakest links in a protocol,
    uncovering protocol design flaws, inferring the existence of unobservable
    communication back-channels among botnet servers, and finding deviations
    of protocol implementations which can be used for fingerprinting. We
    validate our technique by inferring the protocol state-machine from
    Postfix's SMTP implementation and comparing the inferred state-machine to
    the SMTP standard. Further, our experimental results offer new insights
    into MegaD's C &C, showing our technique can be used as a powerful tool
    for defense against botnets.

# Workshops
- title: Pruning Pretrained Encoders with a Multitask Objective
  authors: [Patrick Xia, Richard Shin]
  published:
    - venue: enlsp-neurips
      date: 2021-12-13
  links:
    - pdf: https://arxiv.org/pdf/2112.05705.pdf
  abstract: >
    The sizes of pretrained language models make them challenging and expensive
    to use when there are multiple desired downstream tasks. In this work, we
    adopt recent strategies for model pruning during finetuning to explore the
    question of whether it is possible to prune a single encoder so that it can
    be used for multiple tasks. We allocate a fixed parameter budget and compare
    pruning a single model with a multitask objective against the best ensemble
    of single-task models. We find that under two pruning strategies
    (element-wise and rank pruning), the approach with the multitask objective
    outperforms training models separately when averaged across all tasks, and
    it is competitive on each individual one. Additional analysis finds that
    using a multitask objective during pruning can also be an effective method
    for reducing model sizes for low-resource tasks.

- title: Hierarchical Imitation Learning via Variational Inference of Control Programs
  authors: [Roy Fox, Richard Shin, William Paul, Yitian Zou, Dawn Song, Ken Goldberg, Pieter Abbeel, Ion Stoica]
  published:
    - venue: infer2control-neurips
      date: 2018-12-12
  links:
    - pdf: https://royf.org/pub/pdf/Fox2018Hierarchical.pdf
  abstract: >
    Autonomous controllers can be trained by imitation learning from
    demonstrations of the intended control. Hierarchical imitation learning
    in the parametrized hierarchical procedures (PHP) framework can reduce
    the required number of demonstrations by allowing each procedure to
    specialize in specific behavior and abstract away from transient state
    features. We propose a variational inference method for discovering the
    latent hierarchical structure in observation–action traces of teacher
    demonstrations. We train an inference model to approximate the posterior
    distribution of the latent call-stack of hierarchical procedures, and
    sample from it to guide the training of the hierarchical controller. Our
    method requires 40 demonstrations, less than half as many as end-to-end
    RNN training, to achieve 88% success rate in training the BubbleSort
    algorithm

# \emph{Synthetic Datasets for Neural Program Synthesis} (extended abstract). \\
# Richard Shin, Neel Kant, Kavi Gupta, Christopher Bender, Brandon Trabucco, Rishabh Singh, Dawn Song. \\
# Neural Abstract Machines \& Program Induction Workshop, at ICML, 2018.
#
- title: Imitation Learning of Hierarchical Programs via Variational Inference
  authors: [Roy Fox*, Richard Shin*, Pieter Abbeel, Ken Goldberg, Dawn Song, Ion Stoica]
  published:
    - venue: nampi-icml
      date: 2018-07-15
      format: extended abstract
  links:
    - pdf: https://uclnlp.github.io/nampi/extended_abstracts/fox.pdf

- title: Towards Specification-Directed Program Repair
  authors: [Richard Shin, Dawn Song, Illia Polosukhin]
  published:
    - venue: iclr-workshop
      date: 2018-05-03
  links:
    - pdf: https://openreview.net/pdf?id=B1iZRFkwz
  abstract: >
    Several recent papers have developed neural network program synthesizers
    by using supervised learning over large sets of randomly generated
    programs and specifications. In this paper, we investigate the
    feasibility of this approach for program repair: given a specification
    and a candidate program assumed similar to a correct program for the
    specification, synthesize a program which meets the specification.
    Working in the Karel domain with a dataset of synthetically generated
    candidates, we develop models that can make effective use of the extra
    information in candidate programs, achieving 40% error reduction compared
    to a baseline program synthesis model that only receives the
    specification and not a candidate program.

- title: Differentiable Neural Network Architecture Search
  authors: [Richard Shin*, Charles Packer*, Dawn Song]
  published:
    - venue: iclr-workshop
      date: 2018-05-03
  links:
    - pdf: https://openreview.net/pdf?id=BJ-MRKkwG
  abstract: >
    The successes of deep learning in recent years has been fueled by the
    development of innovative new neural network architectures. However, the
    design of a neural network architecture remains a difficult problem,
    requiring significant human expertise as well as computational resources.
    In this paper, we propose a method for transforming a discrete neural
    network architecture space into a continuous and differentiable form,
    which enables the use of standard gradient-based optimization techniques
    for this problem, and allows us to learn the architecture and the
    parameters simultaneously. We evaluate our methods on the Udacity
    steering angle prediction dataset, and show that our method can discover
    architectures with similar or better predictive accuracy but
    significantly fewer parameters and smaller computational cost.

- title: JPEG-resistant Adversarial Images
  authors: [Richard Shin, Dawn Song]
  published:
    - venue: mlcs-neurips
      date: 2017-12-07
  links:
    - pdf: https://machine-learning-and-security.github.io/papers/mlsec17_paper_54.pdf
  abstract: >
    Several papers have explored the use of JPEG compression as a defense
    against adversarial images. In this work, we show that we can
    generate adversarial images which survive JPEG compression, by including
    a differentiable approximation to JPEG in the target model. By ensembling
    multiple target models employing varying levels of compression, we
    generate adversarial images with up to 691× greater success rate than the
    baseline method on a model using JPEG as defense.

- title: Exploring Privacy Preservation in Outsourced K-Nearest Neighbors with Multiple Data Owners
  authors: [Frank Li, Richard Shin, Vern Paxson]
  published:
    - venue: ccsw-ccs
      date: 2015-10-16
  links:
    - pdf: https://frankli.ece.gatech.edu/papers/li_ppknn_ccsw.pdf
  abstract: >
    The k-nearest neighbors (k-NN) algorithm is a popular and effective
    classification algorithm. Due to its large storage and computational
    requirements, it is suitable for cloud outsourcing. However, k-NN is
    often run on sensitive data such as medical records, user images, or
    personal information. It is important to protect the privacy of data in
    an outsourced k-NN system. Prior works have all assumed the data owners
    (who submit data to the outsourced k-NN system) are a single trusted
    party. However, we observe that in many practical scenarios, there may be
    multiple mutually distrusting data owners. In this work, we present the
    first framing and exploration of privacy preservation in an outsourced
    k-NN system with multiple data owners. We consider the various threat
    models introduced by this modification. We discover that under a
    particularly practical threat model that covers numerous scenarios, there
    exists a set of adaptive attacks that breach the data privacy of any
    exact k-NN system. The vulnerability is a result of the mathematical
    properties of k-NN and its output. Thus, we propose a privacy-preserving
    alternative system supporting kernel density estimation using a Gaussian
    kernel, a classification algorithm from the same family as k-NN. In many
    applications, this similar algorithm serves as a good substitute for
    k-NN. We additionally investigate solutions for other threat models,
    often through extensions on prior single data owner systems.

- title: "The Emperor's New APIs: On the (In)Secure Usage of New Client-side Primitives"
  authors: [Steve Hanna, Richard Shin, Devdatta Akhawe, Arman Boehm, Prateek Saxena, Dawn Song]
  published:
    - venue: w2sp-ieeesp
      date: 2010-05-20
  links:
    - pdf: http://webblaze.cs.berkeley.edu/papers/w2sp2010ena.pdf
  abstract: >
    Several new browser primitives have been proposed to meet the demands of
    application interactivity while enabling security. To investigate whether
    applications consistently use these primitives safely in practice, we
    study the real-world usage of two client-side primitives, namely
    postMessage and HTML5’s client-side database storage. We examine new
    purely client-side communication protocols layered on postMessage
    (Facebook Connect and Google Friend Connect) and several real-world web
    applications (including Gmail, Buzz, Maps and others) which use
    client-side storage abstractions. We find that, in practice, these
    abstractions are used insecurely, which leads to severe vulnerabilities
    and can increase the attack surface for web applications in unexpected
    ways. We conclude the paper by offering insights into why these
    abstractions can potentially be hard to use safely, and propose the
    economy of liabilities principle for designing future abstractions. The
    principle recommends that a good design for a primitive should minimize
    the liability that the user undertakes to ensure application security.
